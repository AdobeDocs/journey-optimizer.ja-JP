---
product: experience platform
solution: Experience Platform
title: AI モデルについて
description: オファーをランク付けできる AI モデルについて説明します
feature: Ranking Formulas
role: User
level: Intermediate
exl-id: 4f7f7d1d-a12a-4ff6-b0ff-1a1c3d305a9d
source-git-commit: f5627a23ceb0d00dd01db8766e72fed1b5d652a3
workflow-type: tm+mt
source-wordcount: '1508'
ht-degree: 3%

---

# AI モデル {#ai-models}

## AI モデルの概要 {#get-started-with-ai-rankings}

[!DNL Journey Optimizer] では、特定のプロファイルに対して表示するオファーをランク付けする、トレーニング済みモデルシステムを使用できます。

>[!CAUTION]
>
>現在、AI モデルの使用は、一部のユーザーのみが早期に利用できます。

この機能を使用すると、異なる **AI モデル** ビジネス目標に基づいて トレーニング済みモデルシステムは、これらの様々な目標ベースの戦略を決定に使用し、様々な AI モデルが目標に与える影響を理解するのに役立ちます。

例えば、E メールチャネル用の AI モデルと、プッシュチャネル用の AI モデルを選択できます。 各チャネルについて、トレーニング済みモデルシステムは、複数のデータポイントを活用して、オファーの優先度スコアや[ランキング式](create-ranking-formulas.md)を考慮するのではなく、特定のプレースメントに対して最初に提示するオファーを決定します。

>[!NOTE]
>
>現在 [!DNL Journey Optimizer] でサポートされている AI ランキングのモデルタイプは、**自動最適化**&#x200B;のみです。

## 自動最適化モデル {#auto-optimization}

自動最適化モデルは、ビジネスクライアントが設定する KPI（リターン）を最大化するオファーを提供することを目的としています。 これらの KPI は、コンバージョン率、売上高などの形式で設定できます。 この時点で、自動最適化は、オファーコンバージョンをターゲットとするオファークリック数の最適化に焦点を当てています。 自動最適化は、パーソナライズされておらず、オファーの「グローバル」パフォーマンスに基づいて最適化されます。

### 用語

自動最適化について説明する際に、次の用語が役立ちます。

* **マルチアームバンディット**: A [マルチアームバンディット](https://en.wikipedia.org/wiki/Multi-armed_bandit){target=&quot;_blank&quot;} 調査学習とその学習の活用のバランスを最適化するアプローチ。

* **トムソンサンプリング**：トンプソンサンプリングは、オンラインでの判定問題に対してアルゴリズムで、即時のパフォーマンスを最大化する既知の要素を活用し、将来のパフォーマンスを向上させる新しい情報を蓄積するために投資する間でバランスを取る必要があります。 [詳細情報](#thompson-sampling)

* [**ベータ版配布**](https://en.wikipedia.org/wiki/Beta_distribution){target=&quot;_blank&quot;}:連続のセット [確率分布](https://en.wikipedia.org/wiki/Probability_distribution)間隔で定義された {target=&quot;_blank&quot;} [0, 1] [パラメータ化](https://en.wikipedia.org/wiki/Statistical_parameter){target=&quot;_blank&quot;} by 2 positive [形状パラメータ](https://en.wikipedia.org/wiki/Shape_parameter){target=&quot;_blank&quot;}。

### トンプソンサンプリング {#thompson-sampling}

自動最適化の基盤となるアルゴリズムは、次のとおりです。 **トンプソンサンプリング**. 本節では、トンプソンサンプリングの背後にある直感について述べた。

[トンプソンサンプリング](https://en.wikipedia.org/wiki/Thompson_sampling){target=&quot;_blank&quot;} （ベイズ帯）は、マルチアームバンディット問題に対するベイズ的アプローチです。  基本的な考え方は、平均報酬を扱うことです??各オファーから **ランダム変数** そして、これまでに収集したデータを使って、平均報酬に関する「信念」を更新します。 この「信念」は、 **後確率分布**  — 基本的には、平均報酬の値の範囲と、各オファーに対する報酬の値が妥当性（または確率）を持つという範囲です。 では、決断ごとに、私たちは次のようにします。 **これらの各後報酬分布から点を試料とする** をクリックし、サンプリングした報酬の値が最も高いオファーを選択します。

このプロセスは、次の図に示すように、3 つの異なるオファーがあります。 最初は、データからの証拠がなく、すべてのオファーに対して、均一な後方報酬分布があると仮定します。 各オファーの後方報酬分布からサンプルを引き出します。 オファー 2 の配布から選択したサンプルの値が最も大きくなります。 これは **探査**. オファー 2 を示した後、以下に説明するベイズ定理を用いて、潜在的な報酬（例えば、コンバージョン/非コンバージョン）を収集し、オファー 2 の後方分布を更新します。  このプロセスを続け、オファーが表示され、報酬が収集されるたびに、後の配分を更新します。 2 番目の図では、オファー 3 が選択されています。オファー 1 の平均報酬が最も高い（後ろの報酬分布は最も右側にある）にもかかわらず、各配分からサンプリングする過程で明らかに最適でないオファー 3 を選択しました。 その際には、Offer 3 の真の報酬分布に関する詳細を学ぶ機会を提供します。

より多くのサンプルが収集されるにつれ、信頼性が高まり、可能な報酬のより正確な推定が得られます（より狭い報酬分布に対応）。 より多くの証拠が得られるにつれ、我々の信念を更新するこのプロセスは、 **ベイズ推論**.

最終的に、あるオファー（オファー 1 など）が明確な勝者である場合、その後の報酬配分は他のオファーとは別になります。 この時点で、各決定に対して、オファー 1 からサンプルされた報酬が最も高い傾向があり、より高い確率で選択します。 これは **搾取**  — 「オファー 1」が最高だという強い信念を持っているので、報酬を最大化するために選ばれています。

![](../assets/ai-ranking-thompson-sampling.png)

**図 1**: *決定ごとに、後方報酬分布からポイントをサンプリングします。 サンプル値（コンバージョン率）が最も高いオファーが選択されます。 最初のフェーズでは、すべてのオファーが均等に配分されます。これは、データからのオファーのコンバージョン率に関する証拠がないからです。 より多くのサンプルを収集すると、後方分布はより狭く、より正確になります。 最終的には、コンバージョン率の最も高いオファーが毎回選択されます。*

<!--
![](../assets/ai-ranking-thompson-sampling-initial.png)
![](../assets/ai-ranking-thompson-sampling-intermediate.png)
![](../assets/ai-ranking-thompson-sampling-ultimate.png)
-->

+++**技術的詳細**

配分を計算/更新するには、 **ベイズ定理**. 各オファー ***i***、我々は彼らの***P(??i | data)***( 例：各オファー ***i***、報酬値の可能性 **??i** は、そのオファーに関してこれまでに収集したデータに基づいて、

ベイズ定理から：

***事後=尤度*前***

この **先行確率** は、出力を生成する確率に関する最初の推測です。 何らかの証拠が収集された後の確率は、 **後確率**. 

自動最適化は、バイナリ報酬（クリック/クリックなし）を考慮するように設計されています。 この場合、可能性は N 件の試行による成功の数を表し、 **二項分布**. ある尤度関数の場合、特定の前の値を選択すると、後の値は前の値と同じ分布になります。 このような前のものを、 **共役前**. このような事前の計算は非常に簡単です。 この **ベータ版配布** は二項確率（二項報酬）より前の共役で、前と後の確率分布にとっては便利で合理的な選択です。ベータ分布は 2 つのパラメータを取ります。 ***α*** および ***β***. これらのパラメーターは、成功と失敗の数、および次の式によって与えられる平均値と考えることができます。

![](../assets/ai-ranking-beta-distribution.png)

前述の可能性関数は二項分布をモデルとしており、成功（コンバージョン）と失敗（コンバージョンなし）と q は [ランダム変数](https://en.wikipedia.org/wiki/Random_variable){target=&quot;_blank&quot;} を [ベータ分布](https://en.wikipedia.org/wiki/Beta_distribution){target=&quot;_blank&quot;}。

前の分布はベータ分布でモデル化され、後の分布は次の形式をとります。

![](../assets/ai-ranking-posterior-distribution.svg)

事後計算は、成功と失敗の数を既存のパラメーターに追加するだけで行われます ***α***, ***β***.

自動最適化の場合は、上の例で示すように、前の配分から始めます ***ベータ (1, 1)*** （均一配布）すべてのオファーに対して、および特定のオファーに対して成功と失敗を得た後、後は、パラメーターを持つベータ配布になります。 ***(s+α、f+β)*** そのオファーに対して
+++

**関連トピック**:

トンプソンサンプリングに関する詳細な調査は、以下の研究論文を参照してください。
* [トンプソンサンプリングの経験的評価](https://proceedings.neurips.cc/paper/2011/file/e53a0a2978c28872a4505bdb51db06dc-Paper.pdf){target=&quot;_blank&quot;}
* [マルチアームバンディット問題に対するトンプソンサンプリングの分析](http://proceedings.mlr.press/v23/agrawal12/agrawal12.pdf){target=&quot;_blank&quot;}

### コールドスタートの問題

「コールドスタート」の問題は、新しいオファーがキャンペーンに追加され、その新しいオファーのコンバージョン率に関するデータがない場合に発生します。 この間に、パフォーマンスの低下を最小限に抑えるために、この新しいオファーを選択する頻度に関する戦略を策定する必要があります。また、この新しいオファーのコンバージョン率に関する情報を収集します。 この問題に対処するには、複数のソリューションを利用できます。 鍵は、この新しいオファーの探索の間のバランスを見つけることです。 現在、新しいオファーのコンバージョン率（以前の配分）を最初に推測する際に、「均一配分」を使用しています。 基本的に、すべてのコンバージョン率の値に同じ確率を割り当てます。


![](../assets/ai-ranking-cold-start-strategies.png)

**図 2**: *3 つのオファーを含むキャンペーンについて考えてみましょう。 キャンペーンがライブ状態の間、オファー 4 がキャンペーンに追加されます。 最初は、オファー 4 のコンバージョン率に関するデータがないので、コールドスタートの問題に対処する必要があります。 当社は、オファー 4 のコンバージョン率に関する最初の推測として均一な配分を使用し、一方で、この新しいオファーのデータを収集します。 詳しくは、 [トンプソンサンプリング](#thompson-sampling) セクションでは、ユーザーに表示するオファーを選択するために、オファーの後方の報酬配分からポイントをサンプリングし、サンプル値が最も高いオファーを選択します。 上の例では、収集した報酬に基づいてオファー 4 を選択し、その後、このオファーの後の配分を更新します。詳しくは、 [トンプソンサンプリング](#thompson-sampling) 」セクションに入力します。*

### 上昇率測定

「上昇率」は、ベースライン戦略（ランダムにオファーを提供）と比較して、ランキングサービスにデプロイされた戦略のパフォーマンスを測定するために使用される指標です。

例えば、ランキングサービスで使用されるトンプソンサンプリング (TS) 戦略のパフォーマンスを測定したい場合、KPI がコンバージョン率 (CVR) である場合、ベースライン戦略に対する TS 戦略の「上昇率」は次のように定義されます。

![](../assets/ai-ranking-lift.png)
