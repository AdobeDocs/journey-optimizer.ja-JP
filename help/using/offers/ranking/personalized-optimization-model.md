---
product: experience platform
solution: Experience Platform
title: パーソナライズされた最適化モデル
description: パーソナライズされた最適化モデルの詳細
feature: Ranking Formulas
role: User
level: Intermediate
exl-id: c73b3092-e96d-4957-88e6-500e99542782
source-git-commit: bfed2a150c1c1568e666d16753b032b203749033
workflow-type: tm+mt
source-wordcount: '799'
ht-degree: 0%

---

# Personalized Optimization モデル {#personalized-optimization-model}

>[!CAUTION]
>
>現在、パーソナライズされた最適化モデルの使用は、一部のユーザーのみが早期にアクセスできます。

## 概要 {#overview}

監視された機械学習とディープラーニングの最先端のテクノロジーを活用することで、ビジネスユーザー（マーケター）はビジネス目標を定義し、顧客データを活用して、パーソナライズされたオファーを提供し、KPI を最大化します。

## 主なモデルの前提と制限 {#key}

自動パーソナライゼーションを使用する利点を最大限に活かすために、いくつかの主な前提と制限事項に注意する必要があります。

* **オファーは十分に異なるので、ユーザーは考慮するオファー間で異なる環境設定をおこないます**. オファーが類似しすぎる場合、結果のモデルは、応答が一見ランダムに見えるので、影響が少なくなります。
例えば、銀行に色の違いのみがある 2 つのクレジットカードオファーがある場合、どのカードを推奨するかは問題になりませんが、各カードに異なる用語がある場合は、特定の顧客が 1 つを選択し、オファー間に十分な違いを与えて、より効果的なモデルを作成します。
* **ユーザートラフィックの構成が安定している**. モデルのトレーニングと予測中にユーザートラフィックの構成が大幅に変化した場合、モデルのパフォーマンスが低下する可能性があります。 例えば、モデルトレーニングフェーズで、セグメント A のユーザーのデータのみを使用でき、セグメント B のユーザーの予測の生成にトレーニング済みモデルを使用すると、モデルのパフォーマンスに影響が出る可能性があります。
* **オファーのパフォーマンスは、短期間で劇的に変化しません** このモデルが毎週更新され、モデルの更新に伴ってパフォーマンスの変更が伝達されるので、 例えば、ある製品は以前非常に人気があったが、公開レポートでは、製品が当社の健康に有害であることが特定され、この製品は非常に速く人気を失います。 このシナリオでは、ユーザーの行動の変更によってモデルが更新されるまで、モデルは引き続きこの製品を予測できます。

## 仕組み {#how}

自動パーソナライゼーションでは、オファー、ユーザーの情報およびコンテキスト情報の間の複雑な機能インタラクションを学習し、パーソナライズされたオファーをエンドユーザーにレコメンデーションします。 フィーチャは、モデルへの入力です。

次の 3 種類の機能があります。

| 機能タイプ | モデルに機能を追加する方法 |
|--------------|----------------------------|
| offer decisioningオブジェクト (placementID、activityID、decisionScopeID) | AEP に送信されるOffer decisioningフィードバックエクスペリエンスイベントの一部 |
| セグメント | ランキング AI モデルを作成する際に、0 ～ 50 個のセグメントを機能として追加できます |
| コンテキストデータ | AEP に送信されるOffer decisioningフィードバックエクスペリエンスイベントの一部。 スキーマに追加できるコンテキストデータ：コマースの詳細、チャネルの詳細、アプリケーションの詳細、Web の詳細、環境の詳細、デバイスの詳細、placeContext |

モデルには、次の 2 つのフェーズがあります。

* 内 **オフラインモデルトレーニング** フェーズでは、モデルは、履歴データでの機能のインタラクションを学習し、記憶することでトレーニングされます。
* 内 **オンライン推論** フェーズでは、モデルで生成されたリアルタイムスコアに基づいてオファーの候補がランク付けされます。 ユーザーやオファーの機能を組み込むのが困難な従来の協調フィルタリング手法とは異なり、自動パーソナライゼーションはディープラーニングベースのレコメンデーション手法で、複雑で非線形の機能のインタラクションパターンを組み込み、学習できます。

以下に、自動パーソナライゼーションの基本的な考え方を簡単に示します。 図 1 に示すように、ユーザーとオファーとの間の過去のインタラクションを保存するデータセットがあるとします。 次のものがあります。
* 2 つのオファー（offer_1 と offer_2）
* 2 つの機能（feature_1 と feature_2）
* 応答列。

feature_1、feature_2 および response の値は 0 または 1 です。 図 1 の青いボックスとオレンジ色のボックスを見ると、offer_1 では feature_1 と feature_2 が同じ値の場合は 1、offer_2 では feature_1 が 0、feature_2 が 1 の場合は 1 となる可能性が高くなります。 また、赤いボックスでは、feature_1 が 0、feature_2 が 1、応答が 0 の場合に offer_1 が提供されることもわかります。 オレンジ色のボックスに表示されるパターンに基づいて、 feature_1 が 0 で feature_2 が 1 の場合、 offer_2 の方がおそらくより適したレコメンデーションです。

基本的に、これは、過去の特徴の操作を学習および記憶し、それらを適用してパーソナライズされた予測を生成するアイデアです。

![](../assets/perso-ranking-schema.png)

## コールドスタートの問題 {#cold-start}

レコメンデーションを行うのに十分なデータがない場合に、コールドスタートの問題が発生します。 自動パーソナライゼーションの場合、2 種類のコールドスタートの問題が発生します。

* **履歴データを含まない新しいランキング戦略を作成した後**&#x200B;の場合、オファーはデータを収集するためにランダムに提供され、データは最初のモデルのトレーニングに使用されます。
* A **最初のモデルがリリースされた後**&#x200B;の場合、合計トラフィックの 10%がランダムサービングに割り当てられ、トラフィックの 90%がモデルのレコメンデーションに使用されます。 したがって、新しいオファーがランキング戦略に追加された場合、そのオファーはトラフィックの 10%の一部として配信されます。 これらのオファーで収集されたデータによって、モデルが引き続き更新されるので、トラフィックの 90%の中から選択する回数が決まります。

## 再トレーニング {#re-training}

モデルは、最新の機能のインタラクションを学習し、毎週のモデルパフォーマンスの低下を軽減するために、再トレーニングされます。
