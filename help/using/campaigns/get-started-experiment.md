---
solution: Journey Optimizer
product: journey optimizer
title: コンテンツ実験の基本を学ぶ
description: Journey Optimizer でのコンテンツ実験について学ぶ
feature: Experimentation
topic: Content Management
role: User
level: Beginner
keywords: 開始, 開始, コンテンツ, 実験
exl-id: 7fe4b24e-f60a-4107-a064-00010b0cbbfc
source-git-commit: 1490ac2efd39c6bf9b6ca97e682750463e9f054d
workflow-type: tm+mt
source-wordcount: '1980'
ht-degree: 100%

---

# コンテンツ実験の基本を学ぶ {#get-started-experiment}

## コンテンツ実験とは

コンテンツ実験を使用すると、キャンペーンにおけるアクションのコンテンツを最適化できます。

実験は一連のランダム化試験です。オンラインテストのコンテキストでは、ランダムに選択された一部のユーザーにはメッセージの特定のバリエーションを表示し、別のランダムに選択された一連のユーザーには別の処理を行うことを意味します。メッセージを送信した後、メールの開封数やクリック数など、興味のある結果指標を測定できます。

## 実験を実行する理由

![](assets/content_experiment_schema.png)

実験を通じて、指標の改善につながる変更を特定できます。上の画像に示すように、ランダムに選択された一部のユーザーは、各処理グループの対象となり、平均してグループは同じ特性を共有します。したがって、結果の違いは、受けた処理の違いによるものと解釈することができます。つまり、加えた変更と、興味のある結果との間の因果関係を確立できます。

これにより、ビジネス目標の最適化において、データに基づく意思決定を行うことができます。

Adobe Journey Optimizer でのコンテンツ実験の場合は、次のようなアイデアをテストできます。

* **件名**：件名のトーンやパーソナライゼーションの度合いの変更は、どのような影響がありますか？
* **メッセージコンテンツ**：電子メールの視覚的なレイアウトを変更すると、メールのクリック数が増えますか？

## コンテンツ実験の仕組み {#content-experiment-work}

### ランダム割り当て

Adobe Journey Optimizer でのコンテンツ実験では、訪問者 ID の擬似ランダムハッシュを使用して、定義した処理の 1 つに対して、ターゲットオーディエンスのユーザーをランダムに割り当てます。ハッシュメカニズムにより、訪問者がキャンペーンに複数回入った場合、その訪問者が決定論的に同じ処理を受けるようにします。

詳しく言えば、MumurHash3 32 ビットアルゴリズムを使用して、ユーザー ID 文字列を 10,000 個のバケットの 1 つにハッシュ化します。トラフィックの 50 ％を各処理に割り当てたコンテンツ実験では、バケット 1 ～ 5,000 に入ったユーザーに最初の処理、バケット 5,001 ～ 10,000 のユーザーに 2 番目の処理を施します。擬似ランダムハッシュが使用されるので、観察する訪問者の割合は 50 - 50 とは限りませんが、統計的には、ターゲットの分割率と同じ割合で分割されます。

コンテンツ実験を伴うすべてのキャンペーンを設定する一環として、ランダム化アルゴリズム用にユーザー ID を選択する ID 名前空間を選択する必要があります。これは、[実行アドレス](../configuration/primary-email-addresses.md)とは無関係です。

### データ収集と分析

割り当て時、すなわちアウトバウンドチャネルでメッセージが送信されたとき、またはインバウンドチャンネルでユーザーがキャンペーンに参加したとき、「割り当てレコード」が適切なシステムデータセットに記録されます。これにより、ユーザーが割り当てられた処理と、実験とキャンペーンの識別情報が記録されます。

目標指標は、次の 2 つの主なクラスにグループ化できます。

* ユーザーが処理に直接反応する直接指標（メールを開く、リンクをクリックするなど）。
* ユーザーが処理された後に発生する、間接指標または「ファネルの底」指標。

Adobe Journey Optimizer がメッセージを追跡する直接的な目標指標の場合、エンドユーザーの応答イベントは、キャンペーン識別子と処理識別子に自動的にタグ付けされ、応答指標と処理を直接関連付けることができます。[トラッキングの詳細情報](../email/message-tracking.md).

![](assets/technote_2.png)

購入などの間接目標または「ファネルの底」目標の場合、エンドユーザーの応答イベントにはキャンペーン識別子と処理識別子がタグ付けされません。つまり、ある購入イベントは処理を受けた後に発生し、その購入と以前の処理割り当てには直接の関連はありません。これらの指標に関して、アドビは、次の場合にファネルコンバージョンイベントの下部に処理を関連付けます。

* ユーザー ID は、割り当て時とコンバージョンイベントで同じです。
* 処理の割り当てから 7 日以内にコンバージョンが発生します。

![](assets/technote_3.png)

次に、Adobe Journey Optimizer は、高度な「いつでも有効な」統計的手法を使用して、この生のレポートデータを解釈し、実験レポートを解釈できるようにします。 詳しくは、[このページ](../campaigns/experiment-calculations.md)を参照してください。

## 実験を実行する際のヒント

実験を実行する場合は、特定のベストプラクティスに従うことが重要です。これらの実験を実行する際のヒントを次に示します。

+++テストしようとしている変数を分離する

テストする仮説をいくつか作成し、配信に影響を与えた原因を判断するために、仮説をできる限り少ない変更点にまで絞り込みます

例えば、電子メールの件名のパーソナライゼーションが開封率を向上させるかどうかを示す仮説が得られます。ただし、メッセージコンテンツや画像に変更を加えると、混乱を招く可能性があります。
+++

+++適切な指標を使用していることを確認する

ターゲットにする指標と、加える変更がこの指標に直接影響を与える可能性があるかどうかを判断します。

例えば、メッセージ本文のコンテンツを変更しても、メールの開封率に影響を与える可能性は低いことなどです。
+++

+++適切なオーディエンスサイズまたは十分に長い期間でテストを実行する

テストを長期間実行すると、処理間の目標指標の違いをより少なく検出できます。ただし、目標指標のベースライン値が小さい場合は、より大きなサンプルサイズが必要になります。
実験に含める必要があるユーザーの数は、検出する効果のサイズ、目標指標の平方偏差または広がり、偽陽性と偽陰性のエラーに対する許容値によって異なります。従来の実験では、[サンプルサイズ計算ツール](https://experienceleague.adobe.com/tools/calculator/testcalculator.html?lang=ja){_blank}を使用して、テストを実行する必要がある期間を決定できます。
+++

+++統計的不確実性について

1,000 人のユーザーが 1 つの処理を見た実験を行い、コンバージョン率を 5%に設定した場合。すべてのユーザーが含まれる場合、これが実質的なコンバージョン率になりますか？真のコンバージョン率はどれくらいですか？
統計的手法は、不確実性を形式化する方法を提供します。オンライン実験を実行する際に最も理解すべき重要な概念の 1 つは、観測されたコンバージョン率が基礎となる真のコンバージョン率の範囲と一致していることで、結論を導き出す前に、これらの推定値が十分に正確になるまで待つ必要があります。信頼区間と信頼性は、この不確実性の定量化に役立ちます。
+++

+++新しい仮説を作成し、継続的にテストする

真のビジネスインサイトを得るには、1 つの実験に集中する必要があります。代わりに、新しい仮説を作成し、様々な変更を加えた新しいテストを様々なオーディエンスで実行し、様々な指標への影響を調べることで、実験を継続します。
+++

## 実験の結果の解釈 {#interpret-results}

>[!CONTEXTUALHELP]
>id="ajo_campaigns_content_experiment_summary"
>title="概要ウィジェット"
>abstract="概要ウィジェットには、結果が決定的かどうかなど、実験結果の概要が表示されます。これにより、実験の結果をすばやく簡単に理解できます。"

![](assets/experimentation_report_3.png)

この節では、実験レポートと表示される様々な統計量を理解する方法について説明します。

コンテンツ実験の結果を解釈する際のガイドラインを次に示します。

結果の完全な説明では、最終的か否かの宣言だけでなく、利用可能なすべての証拠（例：サンプルサイズ、コンバージョン率、信頼区間など）を考慮する必要があります。結果がまだ最終的でない場合でも、ある処理が他と異なるという説得力のある証拠が存在する可能性があります。

統計計算については、この[ページ](../campaigns/experiment-calculations.md)を参照してください。

### 1. 正規化された指標を比較する {#normalized-metrics}

2 つの処理のパフォーマンスを比較する場合は、各処理にさらされたプロファイル数の違いを考慮して、正規化された指標を常に比較する必要があります。

例えば、実験の目標が&#x200B;**[!UICONTROL ユニーク開封数]**&#x200B;に設定され、ユニーク開封数が 200 件記録された 10,000 件のプロファイルに特定の処理が示された場合、これは 2％の&#x200B;**[!UICONTROL コンバージョン率]**&#x200B;を示します。一意でない指標（開封数指標など）の場合、正規化された指標は&#x200B;**[!UICONTROL プロファイルあたりのカウント]**&#x200B;として表示され、価格合計などの連続的な指標の場合、正規化された指標は&#x200B;**[!UICONTROL プロファイルあたりの合計]**&#x200B;として表示されます。

### 2. 信頼区間に焦点を当てる {#confidence-intervals}

プロファイルのサンプルに対して実験を行う場合、特定の処理で観測されたコンバージョン率は、真の基本的なコンバージョン率の推定値を表します。

例えば、処理 A の&#x200B;**[!UICONTROL コンバージョン率]**&#x200B;が 3％で、処理 B の&#x200B;**[!UICONTROL コンバージョン率]**&#x200B;が 2％と観測された場合、処理 A は処理 B よりもパフォーマンスが高いと言えますか？これを回答するには、まず観測されたコンバージョン率の不確実性を定量化する必要があります。

信頼区間は、推定されるコンバージョン率の不確実性の量を定量化するのに役立ちますが、信頼区間の幅が広いほど、不確実性が高くなります。実験に追加されるプロファイルが増えると、区間が小さくなり、より正確な推定値を表します。信頼区間は、観測されたデータと互換性のあるコンバージョン率の範囲を表します。

2 つの処理の信頼区間がほとんど重なっていない場合は、2 つの処理のコンバージョン率が異なることを意味します。しかし、2 つの処理の信頼区間が多く重なっている場合が、2 つの処理のコンバージョン率が同じである可能性が高くなります。

アドビでは 95％の常に有効な信頼区間または信頼シーケンスが使用されています。つまり、実験中はいつでも結果を安全に表示できることを意味します。

### 3. 上昇率について {#understand-lift}

実験レポートの概要には、**[!UICONTROL ベースライン上の上昇率]**&#x200B;が表示されます。ベースラインに対する特定の処理のコンバージョン率の向上率を示す指標です。正確に定義すると、特定の処理とベースラインにおけるパフォーマンスの差を、ベースラインのパフォーマンスで割ったもので、パーセンテージで表します。

### 3. 信頼性について {#understand-confidence}

各処理のパフォーマンスでは主に&#x200B;**[!UICONTROL 信頼区間]**&#x200B;に注目すべきですが、アドビでは、特定の処理がベースライン処理と同じであるという証拠がどれだけあるかという確率的な指標である「信頼性」も示します。信頼性が高いほど、ベースライン処理とベースライン以外の処理のパフォーマンスが同等であるという仮定に対する証拠が少ないことを示します。さらに正確に言えば、表示される信頼性は、実際には真の基礎となるコンバージョン率に差がない場合に、特定の処理とベースラインの間で観察されるコンバージョン率の差が小さくなったであろう確率（パーセント表示）です。p 値に関しては、表示される信頼性は 1 ～ p 値です。

アドビでは、「常に有効な」信頼性と、上記の信頼性シーケンスと一致する「常に有効な」p 値を使用します。

### 4. 統計的優位差

実験を実行する際、特定の処理とベースラインで、真の基礎コンバージョン率やパフォーマンスが同じになるという null 仮説を立て、その結果が観察される可能性が非常に低い場合、統計上有意であると判断されます。

アドビは、信頼性が 95％を超える場合に、実験の最終的な結果が得られることを宣言します。

## 実験を実行した後の作業

実験を実行した後は、次のフォローアップアクションを実行します。

* **優れたアイデアをデプロイ**

  明確な結果が得られたら、すべての顧客に対して最もパフォーマンスの高い処理を提供するか、最もパフォーマンスの高い処理の構造を再現した新しいキャンペーンを作成して、その優れたアイデアを導入します。
  </br>動的環境では、ある時点で正常に動作しても、後に正常に動作しなくなる場合があることに注意してください。

* **フォローアップテストの実行**

  処理の違いを検出するために十分なプロファイルが含まれていない場合、または定義した処理に十分な違いがないなどの理由で、決定的な実験の結果が得られない場合があります。

  テストを行っている仮説がまだ有効である場合、より大きなオーディエンスや異なるオーディエンスに対してフォローアップテストを実行するか、違いがより明確になるように処理を変更することが最適なフォローアップアクションです。

* **より深く掘り下げた分析**

  あるオーディエンスに対して正常に動作した処理であっても、別のオーディエンスに対しては最適な処理ではない場合があります。様々なオーディエンスに対する処理の動作をより深く分析すると、新しいテストのアイデアを生み出すのに役立ちます。

  同様に、各処理のパフォーマンスを異なる指標で調査することで、より包括的な実験の見解が得られる場合があります。

  >[!CAUTION]
  >
  >分析数が多いほど、擬似的な効果や偽陽性を検出する可能性が高くなります。
